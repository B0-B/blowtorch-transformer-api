[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "blowtorch"
version = "1.3.1"
authors = [
  { name="B0-B", email="alch3mist94@protonmail.com" },
]
description = "LLM bootstrap loader for local CPU/GPU inference with fully customizable chat."
readme = "README.md"
requires-python = ">=3.10.12"
classifiers = [
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent"
]
dependencies = [
  "llama-cpp-python>=0.3.2", 
  "accelerate>=0.30.0", 
  "h5py>=3.9.0", 
  "psutil",
  "eager",
  "optimum",
  "auto-gptq==0.7.1",
  "transformers>=4.43.2",
  "tokenizers>=0.19.1",
  "PyPDF2"
]

[project.urls]
Homepage = "https://github.com/B0-B/blowtorch-transformer-api"
Examples = "https://github.com/B0-B/blowtorch-transformer-api/tree/main/examples"
Latest = "pip install https://b0-b.github.io/blowtorch-transformer-api/dist/"